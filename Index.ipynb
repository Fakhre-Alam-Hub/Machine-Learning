{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>INDEX</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "    \n",
    "    What is Machine Learning?\n",
    "    Supervised Learning\n",
    "    Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with One Variable\n",
    "    Model Representation\n",
    "    Cost Function\n",
    "    Cost Function - Intuition I\n",
    "    Cost Function - Intuition II\n",
    "    Gradient Descent\n",
    "    Gradient Descent Intuition\n",
    "    Gradient Descent For Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Multiple Variables\n",
    "    Multiple Features\n",
    "    Gradient Descent for Multiple Variables\n",
    "    Gradient Descent in Practice I - Feature Scaling\n",
    "    Gradient Descent in Practice II - Learning Rate\n",
    "    Features and Polynomial Regression\n",
    "    Normal Equation\n",
    "    Normal Equation Noninvertibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "    Classification\n",
    "    Hypothesis Representation\n",
    "    Decision Boundary\n",
    "    Cost Function\n",
    "    Simplified Cost Function and Gradient Descent\n",
    "    Advanced Optimization\n",
    "    Multiclass Classification: One-vs-all\n",
    "    \n",
    "## Regularization\n",
    "    The Problem of Overfitting\n",
    "    Cost Function\n",
    "    Regularized Linear Regression\n",
    "    Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks: Representation\n",
    "    Non-linear Hypotheses\n",
    "    Neurons and the Brain\n",
    "    Model Representation I\n",
    "    Model Representation II\n",
    "    Examples and Intuitions I\n",
    "    Examples and Intuitions II\n",
    "    Multiclass Classification\n",
    "\n",
    "\n",
    "## Neural Networks: Learning\n",
    "    Cost Function\n",
    "    Backpropagation Algorithm\n",
    "    Backpropagation Intuition\n",
    "    Implementation Note: Unrolling Parameters\n",
    "    Gradient Checking\n",
    "    Random Initialization\n",
    "    Putting It Together\n",
    "    Autonomous Driving\n",
    "\n",
    "## Advice for Applying Machine Learning\n",
    "    Deciding What to Try Next\n",
    "    Evaluating a Hypothesis\n",
    "    Model Selection and Train/Validation/Test Sets\n",
    "    Diagnosing Bias vs. Variance\n",
    "    Regularization and Bias/Variance\n",
    "    Learning Curves\n",
    "    Deciding What to Do Next Revisited\n",
    "    \n",
    "## Machine Learning System Design\n",
    "    Prioritizing What to Work On\n",
    "    Error Analysis\n",
    "    Error Metrics for Skewed Classes\n",
    "    Trading Off Precision and Recall\n",
    "    Data For Machine Learning\n",
    "\n",
    "## Support Vector Machines\n",
    "    Optimization Objective\n",
    "    Large Margin Intuition\n",
    "    Mathematics Behind Large Margin Classification\n",
    "    Kernels I\n",
    "    Kernels II\n",
    "    Using An SVM\n",
    "\n",
    "\n",
    "## Unsupervised Learning\n",
    "    Unsupervised Learning: Introduction\n",
    "    K-Means Algorithm\n",
    "    Optimization Objective\n",
    "    Random Initialization\n",
    "    Choosing the Number of Clusters\n",
    "\n",
    "## Dimensionality Reduction\n",
    "    Motivation I: Data Compression\n",
    "    Motivation II: Visualization\n",
    "    Principal Component Analysis Problem Formulation\n",
    "    Principal Component Analysis Algorithm\n",
    "    Reconstruction from Compressed Representation\n",
    "    Choosing the Number of Principal Components\n",
    "    Advice for Applying PCA\n",
    "    \n",
    "## Anomaly Detection\n",
    "    Problem Motivation\n",
    "    Gaussian Distribution\n",
    "    Algorithm\n",
    "    Developing and Evaluating an Anomaly Detection System\n",
    "    Anomaly Detection vs. Supervised Learning\n",
    "    Choosing What Features to Use\n",
    "    Multivariate Gaussian Distribution\n",
    "    Anomaly Detection using the Multivariate Gaussian Distribution\n",
    "\n",
    "## Recommender Systems\n",
    "    Problem Formulation\n",
    "    Content Based Recommendations\n",
    "    Collaborative Filtering\n",
    "    Collaborative Filtering Algorithm\n",
    "    Vectorization: Low Rank Matrix Factorization\n",
    "    Implementational Detail: Mean Normalization\n",
    "\n",
    "## Large Scale Machine Learning\n",
    "    Learning With Large Datasets\n",
    "    Stochastic Gradient Descent\n",
    "    Mini-Batch Gradient Descent\n",
    "    Stochastic Gradient Descent Convergence\n",
    "    Online Learning\n",
    "    Map Reduce and Data Parallelism\n",
    "\n",
    "## Application Example: Photo OCR\n",
    "    Problem Description and Pipeline\n",
    "    Sliding Windows\n",
    "    Getting Lots of Data and Artificial Data\n",
    "    Ceiling Analysis: What Part of the Pipeline to Work on Next\n",
    "    Summary and Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
